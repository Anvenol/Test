{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'D:\\Study\\深度学习\\日月光华-tensorflow入门与实战资料\\数据集\\Leaf classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "\n",
       "    margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1  0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2  0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3  0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4  0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990 entries, 0 to 989\n",
      "Columns: 194 entries, id to texture64\n",
      "dtypes: float64(192), int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.factorize(data.species)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[data.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((742, 192), (248, 192))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_x.mean(axis=0)\n",
    "std = train_x.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=(train_x-mean)/std\n",
    "test_x=(test_x-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把每一条数据看成一个序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一维卷积或者LSTM sample,step,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-0.476223</td>\n",
       "      <td>-0.428364</td>\n",
       "      <td>3.582414</td>\n",
       "      <td>-0.553485</td>\n",
       "      <td>-0.456149</td>\n",
       "      <td>0.207869</td>\n",
       "      <td>-0.651980</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.370123</td>\n",
       "      <td>-0.921539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192536</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>0.029528</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.866293</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>-0.210288</td>\n",
       "      <td>-0.594373</td>\n",
       "      <td>1.850323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>-0.875791</td>\n",
       "      <td>-0.732971</td>\n",
       "      <td>-0.488174</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.116091</td>\n",
       "      <td>-0.739095</td>\n",
       "      <td>-1.085809</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>3.544298</td>\n",
       "      <td>-1.044225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497732</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>0.783841</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.866293</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>-0.562988</td>\n",
       "      <td>-0.663383</td>\n",
       "      <td>-0.847412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-0.875791</td>\n",
       "      <td>-0.732971</td>\n",
       "      <td>1.288130</td>\n",
       "      <td>4.707151</td>\n",
       "      <td>-0.351340</td>\n",
       "      <td>-0.739095</td>\n",
       "      <td>-0.977352</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>-1.044225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497732</td>\n",
       "      <td>1.502884</td>\n",
       "      <td>-0.446882</td>\n",
       "      <td>-0.176301</td>\n",
       "      <td>0.161372</td>\n",
       "      <td>-0.138474</td>\n",
       "      <td>4.626684</td>\n",
       "      <td>-0.298470</td>\n",
       "      <td>-0.456425</td>\n",
       "      <td>0.828454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>2.620631</td>\n",
       "      <td>3.379062</td>\n",
       "      <td>-0.414166</td>\n",
       "      <td>-0.830342</td>\n",
       "      <td>-0.770575</td>\n",
       "      <td>1.382207</td>\n",
       "      <td>-0.760438</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.164118</td>\n",
       "      <td>-0.430733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561978</td>\n",
       "      <td>4.423552</td>\n",
       "      <td>-0.407164</td>\n",
       "      <td>-0.259064</td>\n",
       "      <td>-0.095594</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>0.202503</td>\n",
       "      <td>0.583265</td>\n",
       "      <td>-0.387487</td>\n",
       "      <td>0.542328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-0.676007</td>\n",
       "      <td>-0.377600</td>\n",
       "      <td>-0.710198</td>\n",
       "      <td>-0.068950</td>\n",
       "      <td>-0.456149</td>\n",
       "      <td>-0.549694</td>\n",
       "      <td>-0.218096</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.164118</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144342</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>1.577830</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.545201</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>-0.562988</td>\n",
       "      <td>0.854116</td>\n",
       "      <td>-0.275159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-0.576115</td>\n",
       "      <td>-0.479127</td>\n",
       "      <td>0.474005</td>\n",
       "      <td>0.623263</td>\n",
       "      <td>-0.456149</td>\n",
       "      <td>-0.019407</td>\n",
       "      <td>-1.085809</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>2.720171</td>\n",
       "      <td>-1.166910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578473</td>\n",
       "      <td>3.431638</td>\n",
       "      <td>-0.288052</td>\n",
       "      <td>-0.259064</td>\n",
       "      <td>0.097114</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>0.465708</td>\n",
       "      <td>-0.663383</td>\n",
       "      <td>-0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1.721553</td>\n",
       "      <td>1.754601</td>\n",
       "      <td>-0.784206</td>\n",
       "      <td>-0.761128</td>\n",
       "      <td>-0.665766</td>\n",
       "      <td>1.571492</td>\n",
       "      <td>-0.435010</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>1.041559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.566045</td>\n",
       "      <td>-0.486559</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.673651</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>1.229857</td>\n",
       "      <td>-0.111591</td>\n",
       "      <td>-0.152522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.621661</td>\n",
       "      <td>0.383906</td>\n",
       "      <td>-1.080275</td>\n",
       "      <td>-0.138164</td>\n",
       "      <td>-0.246477</td>\n",
       "      <td>-0.284541</td>\n",
       "      <td>1.625788</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.164118</td>\n",
       "      <td>2.513913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.561978</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>-0.685067</td>\n",
       "      <td>1.437691</td>\n",
       "      <td>2.152444</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.095367</td>\n",
       "      <td>-0.847412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.023288</td>\n",
       "      <td>-0.529917</td>\n",
       "      <td>-0.044088</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.456149</td>\n",
       "      <td>-0.284541</td>\n",
       "      <td>2.493502</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.782134</td>\n",
       "      <td>2.636599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064042</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>-0.010149</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.352494</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>-0.562988</td>\n",
       "      <td>-0.663383</td>\n",
       "      <td>0.910199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>1.721553</td>\n",
       "      <td>1.856128</td>\n",
       "      <td>-0.192104</td>\n",
       "      <td>-0.276593</td>\n",
       "      <td>-0.770575</td>\n",
       "      <td>1.988266</td>\n",
       "      <td>-0.218096</td>\n",
       "      <td>-0.405625</td>\n",
       "      <td>-0.164118</td>\n",
       "      <td>-0.430733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401345</td>\n",
       "      <td>-0.260532</td>\n",
       "      <td>1.816015</td>\n",
       "      <td>-0.093537</td>\n",
       "      <td>-0.737843</td>\n",
       "      <td>-0.235593</td>\n",
       "      <td>-0.239933</td>\n",
       "      <td>0.083604</td>\n",
       "      <td>-0.663383</td>\n",
       "      <td>2.259087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "341 -0.476223 -0.428364  3.582414 -0.553485 -0.456149  0.207869 -0.651980   \n",
       "737 -0.875791 -0.732971 -0.488174  0.000300  1.116091 -0.739095 -1.085809   \n",
       "471 -0.875791 -0.732971  1.288130  4.707151 -0.351340 -0.739095 -0.977352   \n",
       "909  2.620631  3.379062 -0.414166 -0.830342 -0.770575  1.382207 -0.760438   \n",
       "361 -0.676007 -0.377600 -0.710198 -0.068950 -0.456149 -0.549694 -0.218096   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "357 -0.576115 -0.479127  0.474005  0.623263 -0.456149 -0.019407 -1.085809   \n",
       "449  1.721553  1.754601 -0.784206 -0.761128 -0.665766  1.571492 -0.435010   \n",
       "402  1.621661  0.383906 -1.080275 -0.138164 -0.246477 -0.284541  1.625788   \n",
       "320  0.023288 -0.529917 -0.044088  0.000300 -0.456149 -0.284541  2.493502   \n",
       "904  1.721553  1.856128 -0.192104 -0.276593 -0.770575  1.988266 -0.218096   \n",
       "\n",
       "      margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n",
       "341 -0.405625 -0.370123 -0.921539  ...  -0.192536  -0.260532   0.029528   \n",
       "737 -0.405625  3.544298 -1.044225  ...  -0.497732  -0.260532   0.783841   \n",
       "471 -0.405625  0.041888 -1.044225  ...  -0.497732   1.502884  -0.446882   \n",
       "909 -0.405625 -0.164118 -0.430733  ...  -0.561978   4.423552  -0.407164   \n",
       "361 -0.405625 -0.164118  0.428130  ...  -0.144342  -0.260532   1.577830   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "357 -0.405625  2.720171 -1.166910  ...   0.578473   3.431638  -0.288052   \n",
       "449 -0.405625  0.041888  1.041559  ...  -0.224659   0.566045  -0.486559   \n",
       "402 -0.405625 -0.164118  2.513913  ...  -0.561978  -0.260532  -0.685067   \n",
       "320 -0.405625 -0.782134  2.636599  ...  -0.064042  -0.260532  -0.010149   \n",
       "904 -0.405625 -0.164118 -0.430733  ...  -0.401345  -0.260532   1.816015   \n",
       "\n",
       "     texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "341  -0.465994  -0.866293  -0.235593  -0.239933  -0.210288  -0.594373   \n",
       "737  -0.465994  -0.866293  -0.235593  -0.239933  -0.562988  -0.663383   \n",
       "471  -0.176301   0.161372  -0.138474   4.626684  -0.298470  -0.456425   \n",
       "909  -0.259064  -0.095594  -0.235593   0.202503   0.583265  -0.387487   \n",
       "361  -0.465994  -0.545201  -0.235593  -0.239933  -0.562988   0.854116   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "357  -0.259064   0.097114  -0.235593  -0.239933   0.465708  -0.663383   \n",
       "449  -0.465994  -0.673651  -0.235593  -0.239933   1.229857  -0.111591   \n",
       "402   1.437691   2.152444  -0.235593  -0.239933  -0.004548   0.095367   \n",
       "320  -0.465994  -0.352494  -0.235593  -0.239933  -0.562988  -0.663383   \n",
       "904  -0.093537  -0.737843  -0.235593  -0.239933   0.083604  -0.663383   \n",
       "\n",
       "     texture64  \n",
       "341   1.850323  \n",
       "737  -0.847412  \n",
       "471   0.828454  \n",
       "909   0.542328  \n",
       "361  -0.275159  \n",
       "..         ...  \n",
       "357  -0.683924  \n",
       "449  -0.152522  \n",
       "402  -0.847412  \n",
       "320   0.910199  \n",
       "904   2.259087  \n",
       "\n",
       "[742 rows x 192 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x =np.expand_dims(train_x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 192, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x =np.expand_dims(test_x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =keras.Sequential()\n",
    "model.add(layers.Conv1D(32, 7, input_shape=(train_x.shape[1:]),activation='relu',padding='valid'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 7 ,activation='relu',padding='valid'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(99,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 186, 32)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 56, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 99)                3267      \n",
      "=================================================================\n",
      "Total params: 10,723\n",
      "Trainable params: 10,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 4.5962 - acc: 0.0054 - val_loss: 4.5846 - val_acc: 0.0202\n",
      "Epoch 2/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5747 - acc: 0.0121 - val_loss: 4.5763 - val_acc: 0.0202\n",
      "Epoch 3/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5556 - acc: 0.0108 - val_loss: 4.5620 - val_acc: 0.0282\n",
      "Epoch 4/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5294 - acc: 0.0296 - val_loss: 4.5428 - val_acc: 0.0282\n",
      "Epoch 5/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4967 - acc: 0.0270 - val_loss: 4.5151 - val_acc: 0.0323\n",
      "Epoch 6/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4591 - acc: 0.0189 - val_loss: 4.4859 - val_acc: 0.0323\n",
      "Epoch 7/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.4187 - acc: 0.0256 - val_loss: 4.4508 - val_acc: 0.0242\n",
      "Epoch 8/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3735 - acc: 0.0270 - val_loss: 4.4186 - val_acc: 0.0202\n",
      "Epoch 9/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3289 - acc: 0.0283 - val_loss: 4.3843 - val_acc: 0.0242\n",
      "Epoch 10/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2844 - acc: 0.0337 - val_loss: 4.3546 - val_acc: 0.0282\n",
      "Epoch 11/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.2409 - acc: 0.0270 - val_loss: 4.3220 - val_acc: 0.0282\n",
      "Epoch 12/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1998 - acc: 0.0364 - val_loss: 4.2905 - val_acc: 0.0282\n",
      "Epoch 13/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1604 - acc: 0.0270 - val_loss: 4.2589 - val_acc: 0.0161\n",
      "Epoch 14/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1186 - acc: 0.0323 - val_loss: 4.2216 - val_acc: 0.0161\n",
      "Epoch 15/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0802 - acc: 0.0283 - val_loss: 4.1866 - val_acc: 0.0282\n",
      "Epoch 16/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0405 - acc: 0.0296 - val_loss: 4.1516 - val_acc: 0.0242\n",
      "Epoch 17/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.0002 - acc: 0.0391 - val_loss: 4.1142 - val_acc: 0.0403\n",
      "Epoch 18/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9636 - acc: 0.0485 - val_loss: 4.0768 - val_acc: 0.0363\n",
      "Epoch 19/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.9242 - acc: 0.0472 - val_loss: 4.0350 - val_acc: 0.0484\n",
      "Epoch 20/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8904 - acc: 0.0350 - val_loss: 4.0010 - val_acc: 0.0444\n",
      "Epoch 21/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8543 - acc: 0.0418 - val_loss: 3.9531 - val_acc: 0.0444\n",
      "Epoch 22/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8225 - acc: 0.0526 - val_loss: 3.9302 - val_acc: 0.0363\n",
      "Epoch 23/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7872 - acc: 0.0660 - val_loss: 3.8855 - val_acc: 0.0484\n",
      "Epoch 24/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7577 - acc: 0.0431 - val_loss: 3.8464 - val_acc: 0.0484\n",
      "Epoch 25/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.7287 - acc: 0.0580 - val_loss: 3.8137 - val_acc: 0.0444\n",
      "Epoch 26/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6969 - acc: 0.0660 - val_loss: 3.7923 - val_acc: 0.0565\n",
      "Epoch 27/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6763 - acc: 0.0660 - val_loss: 3.7474 - val_acc: 0.0565\n",
      "Epoch 28/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6441 - acc: 0.0714 - val_loss: 3.7291 - val_acc: 0.0605\n",
      "Epoch 29/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6202 - acc: 0.0849 - val_loss: 3.6980 - val_acc: 0.0645\n",
      "Epoch 30/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6007 - acc: 0.0782 - val_loss: 3.6745 - val_acc: 0.0565\n",
      "Epoch 31/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5745 - acc: 0.0782 - val_loss: 3.6527 - val_acc: 0.0605\n",
      "Epoch 32/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5487 - acc: 0.0916 - val_loss: 3.6160 - val_acc: 0.0605\n",
      "Epoch 33/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5219 - acc: 0.0957 - val_loss: 3.6080 - val_acc: 0.0685\n",
      "Epoch 34/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.5099 - acc: 0.0849 - val_loss: 3.5700 - val_acc: 0.0685\n",
      "Epoch 35/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4869 - acc: 0.0943 - val_loss: 3.5428 - val_acc: 0.1008\n",
      "Epoch 36/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4622 - acc: 0.1119 - val_loss: 3.5333 - val_acc: 0.0887\n",
      "Epoch 37/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4447 - acc: 0.0876 - val_loss: 3.5160 - val_acc: 0.0968\n",
      "Epoch 38/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4253 - acc: 0.1132 - val_loss: 3.4795 - val_acc: 0.0968\n",
      "Epoch 39/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.4018 - acc: 0.1132 - val_loss: 3.4662 - val_acc: 0.1008\n",
      "Epoch 40/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3907 - acc: 0.1186 - val_loss: 3.4597 - val_acc: 0.1048\n",
      "Epoch 41/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3703 - acc: 0.1186 - val_loss: 3.4238 - val_acc: 0.0968\n",
      "Epoch 42/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3535 - acc: 0.1253 - val_loss: 3.4272 - val_acc: 0.0927\n",
      "Epoch 43/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3407 - acc: 0.1348 - val_loss: 3.4021 - val_acc: 0.1129\n",
      "Epoch 44/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3145 - acc: 0.1334 - val_loss: 3.3866 - val_acc: 0.1008\n",
      "Epoch 45/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2998 - acc: 0.1294 - val_loss: 3.3710 - val_acc: 0.1331\n",
      "Epoch 46/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2881 - acc: 0.1456 - val_loss: 3.3505 - val_acc: 0.1290\n",
      "Epoch 47/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2716 - acc: 0.1429 - val_loss: 3.3423 - val_acc: 0.1008\n",
      "Epoch 48/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2543 - acc: 0.1456 - val_loss: 3.3316 - val_acc: 0.1008\n",
      "Epoch 49/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2447 - acc: 0.1361 - val_loss: 3.3057 - val_acc: 0.1371\n",
      "Epoch 50/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.2274 - acc: 0.1658 - val_loss: 3.3129 - val_acc: 0.0968\n",
      "Epoch 51/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2159 - acc: 0.1429 - val_loss: 3.2884 - val_acc: 0.1331\n",
      "Epoch 52/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1922 - acc: 0.1671 - val_loss: 3.2751 - val_acc: 0.1048\n",
      "Epoch 53/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1845 - acc: 0.1442 - val_loss: 3.2506 - val_acc: 0.1532\n",
      "Epoch 54/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1655 - acc: 0.1617 - val_loss: 3.2431 - val_acc: 0.1089\n",
      "Epoch 55/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1567 - acc: 0.1604 - val_loss: 3.2313 - val_acc: 0.1250\n",
      "Epoch 56/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1389 - acc: 0.1523 - val_loss: 3.2162 - val_acc: 0.1290\n",
      "Epoch 57/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1289 - acc: 0.1429 - val_loss: 3.1908 - val_acc: 0.1411\n",
      "Epoch 58/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1189 - acc: 0.1698 - val_loss: 3.1929 - val_acc: 0.1532\n",
      "Epoch 59/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1026 - acc: 0.1685 - val_loss: 3.1674 - val_acc: 0.1290\n",
      "Epoch 60/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0822 - acc: 0.1563 - val_loss: 3.1701 - val_acc: 0.1492\n",
      "Epoch 61/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0918 - acc: 0.1765 - val_loss: 3.1376 - val_acc: 0.1452\n",
      "Epoch 62/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0658 - acc: 0.1887 - val_loss: 3.1402 - val_acc: 0.1532\n",
      "Epoch 63/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0492 - acc: 0.1792 - val_loss: 3.1420 - val_acc: 0.1452\n",
      "Epoch 64/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0555 - acc: 0.1671 - val_loss: 3.1438 - val_acc: 0.1411\n",
      "Epoch 65/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0286 - acc: 0.1914 - val_loss: 3.1318 - val_acc: 0.1653\n",
      "Epoch 66/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0151 - acc: 0.1941 - val_loss: 3.0823 - val_acc: 0.1774\n",
      "Epoch 67/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0145 - acc: 0.1739 - val_loss: 3.0807 - val_acc: 0.1774\n",
      "Epoch 68/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9939 - acc: 0.1927 - val_loss: 3.1068 - val_acc: 0.1371\n",
      "Epoch 69/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9793 - acc: 0.2008 - val_loss: 3.0920 - val_acc: 0.1492\n",
      "Epoch 70/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.9765 - acc: 0.2008 - val_loss: 3.0444 - val_acc: 0.1815\n",
      "Epoch 71/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9540 - acc: 0.2008 - val_loss: 3.0375 - val_acc: 0.1694\n",
      "Epoch 72/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9590 - acc: 0.1873 - val_loss: 3.0412 - val_acc: 0.1573\n",
      "Epoch 73/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9357 - acc: 0.2129 - val_loss: 3.0288 - val_acc: 0.1774\n",
      "Epoch 74/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9404 - acc: 0.1873 - val_loss: 3.0340 - val_acc: 0.1815\n",
      "Epoch 75/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9190 - acc: 0.2291 - val_loss: 3.0506 - val_acc: 0.1331\n",
      "Epoch 76/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9173 - acc: 0.2089 - val_loss: 3.0358 - val_acc: 0.1774\n",
      "Epoch 77/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9109 - acc: 0.2224 - val_loss: 3.0009 - val_acc: 0.1976\n",
      "Epoch 78/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8904 - acc: 0.2183 - val_loss: 2.9987 - val_acc: 0.1855\n",
      "Epoch 79/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8762 - acc: 0.2332 - val_loss: 2.9896 - val_acc: 0.1855\n",
      "Epoch 80/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8704 - acc: 0.2453 - val_loss: 3.0243 - val_acc: 0.1774\n",
      "Epoch 81/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8683 - acc: 0.2143 - val_loss: 2.9788 - val_acc: 0.1976\n",
      "Epoch 82/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8521 - acc: 0.2210 - val_loss: 2.9232 - val_acc: 0.2218\n",
      "Epoch 83/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8462 - acc: 0.2224 - val_loss: 2.9308 - val_acc: 0.1855\n",
      "Epoch 84/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8368 - acc: 0.2385 - val_loss: 2.9357 - val_acc: 0.1694\n",
      "Epoch 85/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8204 - acc: 0.2547 - val_loss: 2.9353 - val_acc: 0.1694\n",
      "Epoch 86/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8168 - acc: 0.2291 - val_loss: 2.9049 - val_acc: 0.1653\n",
      "Epoch 87/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8063 - acc: 0.2332 - val_loss: 2.9103 - val_acc: 0.1976\n",
      "Epoch 88/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8048 - acc: 0.2278 - val_loss: 2.9066 - val_acc: 0.1815\n",
      "Epoch 89/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7896 - acc: 0.2439 - val_loss: 2.8990 - val_acc: 0.2056\n",
      "Epoch 90/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7879 - acc: 0.2197 - val_loss: 2.9174 - val_acc: 0.1895\n",
      "Epoch 91/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7735 - acc: 0.2332 - val_loss: 2.8932 - val_acc: 0.1653\n",
      "Epoch 92/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7701 - acc: 0.2534 - val_loss: 2.8675 - val_acc: 0.1734\n",
      "Epoch 93/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7574 - acc: 0.2507 - val_loss: 2.8417 - val_acc: 0.2339\n",
      "Epoch 94/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7453 - acc: 0.2466 - val_loss: 2.8785 - val_acc: 0.2056\n",
      "Epoch 95/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7394 - acc: 0.2682 - val_loss: 2.8769 - val_acc: 0.2056\n",
      "Epoch 96/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7427 - acc: 0.2628 - val_loss: 2.8132 - val_acc: 0.2218\n",
      "Epoch 97/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7185 - acc: 0.2911 - val_loss: 2.8537 - val_acc: 0.1976\n",
      "Epoch 98/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7133 - acc: 0.2588 - val_loss: 2.8028 - val_acc: 0.2419\n",
      "Epoch 99/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6882 - acc: 0.2844 - val_loss: 2.8366 - val_acc: 0.2298\n",
      "Epoch 100/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6956 - acc: 0.2615 - val_loss: 2.8283 - val_acc: 0.1976\n",
      "Epoch 101/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6811 - acc: 0.2642 - val_loss: 2.7524 - val_acc: 0.2298\n",
      "Epoch 102/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6895 - acc: 0.2642 - val_loss: 2.8078 - val_acc: 0.2177\n",
      "Epoch 103/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6611 - acc: 0.2844 - val_loss: 2.7588 - val_acc: 0.2379\n",
      "Epoch 104/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6506 - acc: 0.2817 - val_loss: 2.7924 - val_acc: 0.2056\n",
      "Epoch 105/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6700 - acc: 0.2520 - val_loss: 2.8120 - val_acc: 0.2177\n",
      "Epoch 106/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6317 - acc: 0.2668 - val_loss: 2.7716 - val_acc: 0.2218\n",
      "Epoch 107/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6342 - acc: 0.2574 - val_loss: 2.7834 - val_acc: 0.2137\n",
      "Epoch 108/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6270 - acc: 0.2722 - val_loss: 2.7736 - val_acc: 0.2056\n",
      "Epoch 109/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6227 - acc: 0.2965 - val_loss: 2.7347 - val_acc: 0.2298\n",
      "Epoch 110/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6192 - acc: 0.2884 - val_loss: 2.7243 - val_acc: 0.2419\n",
      "Epoch 111/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6113 - acc: 0.2884 - val_loss: 2.7390 - val_acc: 0.2339\n",
      "Epoch 112/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5776 - acc: 0.2911 - val_loss: 2.7152 - val_acc: 0.2258\n",
      "Epoch 113/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5836 - acc: 0.2871 - val_loss: 2.6948 - val_acc: 0.2419\n",
      "Epoch 114/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5865 - acc: 0.2978 - val_loss: 2.7344 - val_acc: 0.2379\n",
      "Epoch 115/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5666 - acc: 0.3005 - val_loss: 2.7031 - val_acc: 0.2500\n",
      "Epoch 116/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5587 - acc: 0.2871 - val_loss: 2.6913 - val_acc: 0.2540\n",
      "Epoch 117/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5644 - acc: 0.2817 - val_loss: 2.6615 - val_acc: 0.2500\n",
      "Epoch 118/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5582 - acc: 0.3005 - val_loss: 2.6835 - val_acc: 0.2621\n",
      "Epoch 119/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5379 - acc: 0.2978 - val_loss: 2.6774 - val_acc: 0.2500\n",
      "Epoch 120/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5300 - acc: 0.3005 - val_loss: 2.7272 - val_acc: 0.2137\n",
      "Epoch 121/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5302 - acc: 0.3073 - val_loss: 2.7078 - val_acc: 0.2500\n",
      "Epoch 122/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5192 - acc: 0.2911 - val_loss: 2.6358 - val_acc: 0.2782\n",
      "Epoch 123/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5067 - acc: 0.3208 - val_loss: 2.6158 - val_acc: 0.2379\n",
      "Epoch 124/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5082 - acc: 0.3019 - val_loss: 2.6431 - val_acc: 0.2782\n",
      "Epoch 125/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4912 - acc: 0.3261 - val_loss: 2.6231 - val_acc: 0.2581\n",
      "Epoch 126/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4763 - acc: 0.3275 - val_loss: 2.6467 - val_acc: 0.2581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4757 - acc: 0.3261 - val_loss: 2.6347 - val_acc: 0.2944\n",
      "Epoch 128/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4779 - acc: 0.3261 - val_loss: 2.6013 - val_acc: 0.2944\n",
      "Epoch 129/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4730 - acc: 0.3127 - val_loss: 2.6104 - val_acc: 0.2581\n",
      "Epoch 130/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4415 - acc: 0.3315 - val_loss: 2.6096 - val_acc: 0.2702\n",
      "Epoch 131/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4503 - acc: 0.3208 - val_loss: 2.5924 - val_acc: 0.2863\n",
      "Epoch 132/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4485 - acc: 0.3086 - val_loss: 2.5939 - val_acc: 0.2903\n",
      "Epoch 133/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4388 - acc: 0.3410 - val_loss: 2.6007 - val_acc: 0.2944\n",
      "Epoch 134/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4181 - acc: 0.3518 - val_loss: 2.6013 - val_acc: 0.2581\n",
      "Epoch 135/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4179 - acc: 0.3342 - val_loss: 2.5797 - val_acc: 0.2702\n",
      "Epoch 136/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4191 - acc: 0.3059 - val_loss: 2.5559 - val_acc: 0.2661\n",
      "Epoch 137/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3971 - acc: 0.3208 - val_loss: 2.5691 - val_acc: 0.2702\n",
      "Epoch 138/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3828 - acc: 0.3410 - val_loss: 2.5721 - val_acc: 0.2661\n",
      "Epoch 139/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3749 - acc: 0.3504 - val_loss: 2.5631 - val_acc: 0.2984\n",
      "Epoch 140/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3745 - acc: 0.3679 - val_loss: 2.5741 - val_acc: 0.2782\n",
      "Epoch 141/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3892 - acc: 0.3410 - val_loss: 2.5596 - val_acc: 0.2782\n",
      "Epoch 142/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3791 - acc: 0.3369 - val_loss: 2.5400 - val_acc: 0.3306\n",
      "Epoch 143/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3559 - acc: 0.3760 - val_loss: 2.5357 - val_acc: 0.2944\n",
      "Epoch 144/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3506 - acc: 0.3652 - val_loss: 2.4799 - val_acc: 0.3105\n",
      "Epoch 145/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3364 - acc: 0.3518 - val_loss: 2.5111 - val_acc: 0.3145\n",
      "Epoch 146/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3359 - acc: 0.3518 - val_loss: 2.5252 - val_acc: 0.3105\n",
      "Epoch 147/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3466 - acc: 0.3491 - val_loss: 2.5340 - val_acc: 0.2782\n",
      "Epoch 148/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3186 - acc: 0.3720 - val_loss: 2.4852 - val_acc: 0.3508\n",
      "Epoch 149/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3147 - acc: 0.3625 - val_loss: 2.5273 - val_acc: 0.3145\n",
      "Epoch 150/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3224 - acc: 0.3531 - val_loss: 2.5350 - val_acc: 0.2742\n",
      "Epoch 151/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3066 - acc: 0.3585 - val_loss: 2.5110 - val_acc: 0.3306\n",
      "Epoch 152/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2845 - acc: 0.3854 - val_loss: 2.5190 - val_acc: 0.2903\n",
      "Epoch 153/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2935 - acc: 0.3774 - val_loss: 2.4345 - val_acc: 0.3226\n",
      "Epoch 154/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2924 - acc: 0.3625 - val_loss: 2.4934 - val_acc: 0.2621\n",
      "Epoch 155/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2779 - acc: 0.3787 - val_loss: 2.4727 - val_acc: 0.3065\n",
      "Epoch 156/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2706 - acc: 0.3720 - val_loss: 2.4492 - val_acc: 0.3266\n",
      "Epoch 157/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2710 - acc: 0.3814 - val_loss: 2.4817 - val_acc: 0.2863\n",
      "Epoch 158/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2498 - acc: 0.3854 - val_loss: 2.4684 - val_acc: 0.3024\n",
      "Epoch 159/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2560 - acc: 0.3949 - val_loss: 2.4214 - val_acc: 0.3065\n",
      "Epoch 160/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2523 - acc: 0.3679 - val_loss: 2.4949 - val_acc: 0.3065\n",
      "Epoch 161/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2465 - acc: 0.3544 - val_loss: 2.4374 - val_acc: 0.3710\n",
      "Epoch 162/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2414 - acc: 0.3814 - val_loss: 2.4619 - val_acc: 0.3065\n",
      "Epoch 163/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2203 - acc: 0.4030 - val_loss: 2.4533 - val_acc: 0.2621\n",
      "Epoch 164/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2163 - acc: 0.3774 - val_loss: 2.4545 - val_acc: 0.2863\n",
      "Epoch 165/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2103 - acc: 0.4084 - val_loss: 2.4475 - val_acc: 0.3105\n",
      "Epoch 166/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1879 - acc: 0.3989 - val_loss: 2.4914 - val_acc: 0.2621\n",
      "Epoch 167/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2045 - acc: 0.3868 - val_loss: 2.3905 - val_acc: 0.3427\n",
      "Epoch 168/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1952 - acc: 0.3908 - val_loss: 2.3902 - val_acc: 0.3306\n",
      "Epoch 169/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1922 - acc: 0.3787 - val_loss: 2.4347 - val_acc: 0.3548\n",
      "Epoch 170/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1883 - acc: 0.3881 - val_loss: 2.3832 - val_acc: 0.3468\n",
      "Epoch 171/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1644 - acc: 0.4111 - val_loss: 2.3701 - val_acc: 0.3387\n",
      "Epoch 172/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1823 - acc: 0.3949 - val_loss: 2.4332 - val_acc: 0.3347\n",
      "Epoch 173/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1716 - acc: 0.4030 - val_loss: 2.4312 - val_acc: 0.3185\n",
      "Epoch 174/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1726 - acc: 0.3841 - val_loss: 2.3709 - val_acc: 0.3306\n",
      "Epoch 175/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1548 - acc: 0.4030 - val_loss: 2.3549 - val_acc: 0.3468\n",
      "Epoch 176/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1262 - acc: 0.4232 - val_loss: 2.3594 - val_acc: 0.3226\n",
      "Epoch 177/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1629 - acc: 0.3949 - val_loss: 2.3769 - val_acc: 0.2944\n",
      "Epoch 178/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1307 - acc: 0.4111 - val_loss: 2.3303 - val_acc: 0.3548\n",
      "Epoch 179/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1152 - acc: 0.4164 - val_loss: 2.3462 - val_acc: 0.3185\n",
      "Epoch 180/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1193 - acc: 0.4191 - val_loss: 2.3420 - val_acc: 0.3589\n",
      "Epoch 181/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1060 - acc: 0.4205 - val_loss: 2.3638 - val_acc: 0.3548\n",
      "Epoch 182/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1198 - acc: 0.4137 - val_loss: 2.3169 - val_acc: 0.3145\n",
      "Epoch 183/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1091 - acc: 0.4245 - val_loss: 2.3176 - val_acc: 0.3669\n",
      "Epoch 184/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0859 - acc: 0.4353 - val_loss: 2.3412 - val_acc: 0.3226\n",
      "Epoch 185/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0842 - acc: 0.4259 - val_loss: 2.2650 - val_acc: 0.3468\n",
      "Epoch 186/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1023 - acc: 0.4178 - val_loss: 2.3855 - val_acc: 0.3427\n",
      "Epoch 187/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0693 - acc: 0.4380 - val_loss: 2.3566 - val_acc: 0.3387\n",
      "Epoch 188/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0883 - acc: 0.4151 - val_loss: 2.3350 - val_acc: 0.3347\n",
      "Epoch 189/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0562 - acc: 0.4407 - val_loss: 2.3812 - val_acc: 0.3226\n",
      "Epoch 190/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0636 - acc: 0.4191 - val_loss: 2.3460 - val_acc: 0.3548\n",
      "Epoch 191/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0542 - acc: 0.4299 - val_loss: 2.2959 - val_acc: 0.3548\n",
      "Epoch 192/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0552 - acc: 0.4124 - val_loss: 2.2967 - val_acc: 0.3387\n",
      "Epoch 193/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0448 - acc: 0.4474 - val_loss: 2.2861 - val_acc: 0.3750\n",
      "Epoch 194/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0359 - acc: 0.4367 - val_loss: 2.2707 - val_acc: 0.3710\n",
      "Epoch 195/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0285 - acc: 0.4286 - val_loss: 2.2608 - val_acc: 0.3669\n",
      "Epoch 196/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0356 - acc: 0.4272 - val_loss: 2.2601 - val_acc: 0.3790\n",
      "Epoch 197/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0135 - acc: 0.4636 - val_loss: 2.2730 - val_acc: 0.3548\n",
      "Epoch 198/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0066 - acc: 0.4488 - val_loss: 2.2556 - val_acc: 0.3589\n",
      "Epoch 199/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.0285 - acc: 0.4394 - val_loss: 2.2339 - val_acc: 0.3468\n",
      "Epoch 200/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9956 - acc: 0.4394 - val_loss: 2.2490 - val_acc: 0.3871\n",
      "Epoch 201/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9874 - acc: 0.4555 - val_loss: 2.2224 - val_acc: 0.3750\n",
      "Epoch 202/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0059 - acc: 0.4474 - val_loss: 2.2776 - val_acc: 0.3468\n",
      "Epoch 203/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9781 - acc: 0.4569 - val_loss: 2.2250 - val_acc: 0.3790\n",
      "Epoch 204/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9779 - acc: 0.4515 - val_loss: 2.2515 - val_acc: 0.3589\n",
      "Epoch 205/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9750 - acc: 0.4380 - val_loss: 2.2358 - val_acc: 0.3589\n",
      "Epoch 206/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9638 - acc: 0.4717 - val_loss: 2.2198 - val_acc: 0.3750\n",
      "Epoch 207/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9640 - acc: 0.4609 - val_loss: 2.2636 - val_acc: 0.3669\n",
      "Epoch 208/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9458 - acc: 0.4663 - val_loss: 2.2100 - val_acc: 0.3831\n",
      "Epoch 209/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9646 - acc: 0.4677 - val_loss: 2.1959 - val_acc: 0.3750\n",
      "Epoch 210/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9500 - acc: 0.4717 - val_loss: 2.1963 - val_acc: 0.3750\n",
      "Epoch 211/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9446 - acc: 0.4744 - val_loss: 2.2499 - val_acc: 0.3306\n",
      "Epoch 212/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9428 - acc: 0.4488 - val_loss: 2.2185 - val_acc: 0.3831\n",
      "Epoch 213/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9218 - acc: 0.4528 - val_loss: 2.1844 - val_acc: 0.3589\n",
      "Epoch 214/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9276 - acc: 0.4717 - val_loss: 2.2020 - val_acc: 0.3790\n",
      "Epoch 215/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9157 - acc: 0.4852 - val_loss: 2.2353 - val_acc: 0.3669\n",
      "Epoch 216/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9210 - acc: 0.4677 - val_loss: 2.1674 - val_acc: 0.3992\n",
      "Epoch 217/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9263 - acc: 0.4690 - val_loss: 2.1426 - val_acc: 0.3871\n",
      "Epoch 218/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9059 - acc: 0.4757 - val_loss: 2.1729 - val_acc: 0.3589\n",
      "Epoch 219/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.8932 - acc: 0.4892 - val_loss: 2.1803 - val_acc: 0.4476\n",
      "Epoch 220/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9098 - acc: 0.4609 - val_loss: 2.1604 - val_acc: 0.4073\n",
      "Epoch 221/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8914 - acc: 0.4865 - val_loss: 2.2221 - val_acc: 0.3992\n",
      "Epoch 222/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8934 - acc: 0.4717 - val_loss: 2.2047 - val_acc: 0.4153\n",
      "Epoch 223/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8752 - acc: 0.5067 - val_loss: 2.1566 - val_acc: 0.3911\n",
      "Epoch 224/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.8894 - acc: 0.4892 - val_loss: 2.2166 - val_acc: 0.3508\n",
      "Epoch 225/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8776 - acc: 0.4919 - val_loss: 2.1378 - val_acc: 0.4234\n",
      "Epoch 226/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8688 - acc: 0.4811 - val_loss: 2.1421 - val_acc: 0.4315\n",
      "Epoch 227/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8666 - acc: 0.5054 - val_loss: 2.1457 - val_acc: 0.3790\n",
      "Epoch 228/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8674 - acc: 0.4838 - val_loss: 2.1480 - val_acc: 0.3911\n",
      "Epoch 229/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8507 - acc: 0.5027 - val_loss: 2.1484 - val_acc: 0.3790\n",
      "Epoch 230/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.8348 - acc: 0.5108 - val_loss: 2.1661 - val_acc: 0.3750\n",
      "Epoch 231/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8565 - acc: 0.4960 - val_loss: 2.1224 - val_acc: 0.3911\n",
      "Epoch 232/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8611 - acc: 0.4757 - val_loss: 2.1254 - val_acc: 0.4032\n",
      "Epoch 233/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8322 - acc: 0.5027 - val_loss: 2.1327 - val_acc: 0.4315\n",
      "Epoch 234/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8289 - acc: 0.5013 - val_loss: 2.1576 - val_acc: 0.4234\n",
      "Epoch 235/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8178 - acc: 0.5000 - val_loss: 2.1170 - val_acc: 0.4113\n",
      "Epoch 236/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8411 - acc: 0.4987 - val_loss: 2.1783 - val_acc: 0.3790\n",
      "Epoch 237/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8209 - acc: 0.5162 - val_loss: 2.1380 - val_acc: 0.3871\n",
      "Epoch 238/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8139 - acc: 0.4892 - val_loss: 2.0940 - val_acc: 0.4153\n",
      "Epoch 239/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8169 - acc: 0.5108 - val_loss: 2.0740 - val_acc: 0.4597\n",
      "Epoch 240/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7985 - acc: 0.5067 - val_loss: 2.1263 - val_acc: 0.3952\n",
      "Epoch 241/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7828 - acc: 0.5121 - val_loss: 2.0895 - val_acc: 0.4194\n",
      "Epoch 242/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7756 - acc: 0.5283 - val_loss: 2.1496 - val_acc: 0.3669\n",
      "Epoch 243/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8080 - acc: 0.4906 - val_loss: 2.1190 - val_acc: 0.3911\n",
      "Epoch 244/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7868 - acc: 0.5162 - val_loss: 2.1135 - val_acc: 0.4274\n",
      "Epoch 245/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7735 - acc: 0.5148 - val_loss: 2.1186 - val_acc: 0.3911\n",
      "Epoch 246/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7733 - acc: 0.5310 - val_loss: 2.0751 - val_acc: 0.3952\n",
      "Epoch 247/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7759 - acc: 0.5054 - val_loss: 2.0812 - val_acc: 0.3952\n",
      "Epoch 248/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7349 - acc: 0.5391 - val_loss: 2.1004 - val_acc: 0.4113\n",
      "Epoch 249/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7695 - acc: 0.5040 - val_loss: 2.1464 - val_acc: 0.3750\n",
      "Epoch 250/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7618 - acc: 0.5054 - val_loss: 2.0672 - val_acc: 0.4194\n",
      "Epoch 251/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7371 - acc: 0.5283 - val_loss: 2.0852 - val_acc: 0.4073\n",
      "Epoch 252/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7468 - acc: 0.5229 - val_loss: 2.0132 - val_acc: 0.4597\n",
      "Epoch 253/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7387 - acc: 0.5418 - val_loss: 2.0528 - val_acc: 0.4274\n",
      "Epoch 254/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7593 - acc: 0.5283 - val_loss: 2.0842 - val_acc: 0.4153\n",
      "Epoch 255/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7128 - acc: 0.5472 - val_loss: 2.0614 - val_acc: 0.4556\n",
      "Epoch 256/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7442 - acc: 0.5162 - val_loss: 2.0615 - val_acc: 0.4355\n",
      "Epoch 257/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7208 - acc: 0.5229 - val_loss: 2.0387 - val_acc: 0.3992\n",
      "Epoch 258/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7333 - acc: 0.5256 - val_loss: 2.0454 - val_acc: 0.4073\n",
      "Epoch 259/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6960 - acc: 0.5377 - val_loss: 2.0197 - val_acc: 0.4395\n",
      "Epoch 260/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7028 - acc: 0.5485 - val_loss: 2.0429 - val_acc: 0.4032\n",
      "Epoch 261/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7060 - acc: 0.5337 - val_loss: 2.0768 - val_acc: 0.4194\n",
      "Epoch 262/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6992 - acc: 0.5202 - val_loss: 2.0929 - val_acc: 0.4032\n",
      "Epoch 263/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6954 - acc: 0.5323 - val_loss: 2.0813 - val_acc: 0.4315\n",
      "Epoch 264/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6931 - acc: 0.5323 - val_loss: 2.0148 - val_acc: 0.4073\n",
      "Epoch 265/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6867 - acc: 0.5364 - val_loss: 2.0463 - val_acc: 0.4315\n",
      "Epoch 266/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6555 - acc: 0.5606 - val_loss: 2.0689 - val_acc: 0.4113\n",
      "Epoch 267/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6722 - acc: 0.5485 - val_loss: 2.0260 - val_acc: 0.4153\n",
      "Epoch 268/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6762 - acc: 0.5350 - val_loss: 2.0012 - val_acc: 0.4274\n",
      "Epoch 269/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6548 - acc: 0.5418 - val_loss: 2.0040 - val_acc: 0.4315\n",
      "Epoch 270/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6655 - acc: 0.5472 - val_loss: 2.0179 - val_acc: 0.4355\n",
      "Epoch 271/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6537 - acc: 0.5633 - val_loss: 1.9898 - val_acc: 0.4879\n",
      "Epoch 272/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6410 - acc: 0.5795 - val_loss: 1.9959 - val_acc: 0.4718\n",
      "Epoch 273/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6570 - acc: 0.5593 - val_loss: 2.0712 - val_acc: 0.3831\n",
      "Epoch 274/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6405 - acc: 0.5553 - val_loss: 2.0341 - val_acc: 0.4435\n",
      "Epoch 275/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6364 - acc: 0.5633 - val_loss: 1.9885 - val_acc: 0.4274\n",
      "Epoch 276/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6430 - acc: 0.5445 - val_loss: 1.9843 - val_acc: 0.4073\n",
      "Epoch 277/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6397 - acc: 0.5553 - val_loss: 2.0108 - val_acc: 0.4113\n",
      "Epoch 278/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6279 - acc: 0.5485 - val_loss: 2.0154 - val_acc: 0.4516\n",
      "Epoch 279/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5957 - acc: 0.5728 - val_loss: 2.0202 - val_acc: 0.4032\n",
      "Epoch 280/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6103 - acc: 0.5728 - val_loss: 1.9946 - val_acc: 0.4234\n",
      "Epoch 281/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6231 - acc: 0.5633 - val_loss: 1.9942 - val_acc: 0.4315\n",
      "Epoch 282/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6093 - acc: 0.5674 - val_loss: 2.0324 - val_acc: 0.4234\n",
      "Epoch 283/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6269 - acc: 0.5606 - val_loss: 1.9824 - val_acc: 0.4637\n",
      "Epoch 284/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5992 - acc: 0.5795 - val_loss: 2.0781 - val_acc: 0.4274\n",
      "Epoch 285/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5951 - acc: 0.5728 - val_loss: 1.9745 - val_acc: 0.4435\n",
      "Epoch 286/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6131 - acc: 0.5526 - val_loss: 1.9549 - val_acc: 0.4637\n",
      "Epoch 287/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5993 - acc: 0.5741 - val_loss: 1.9574 - val_acc: 0.4355\n",
      "Epoch 288/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5801 - acc: 0.5755 - val_loss: 1.9410 - val_acc: 0.4718\n",
      "Epoch 289/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5926 - acc: 0.5499 - val_loss: 1.9325 - val_acc: 0.4597\n",
      "Epoch 290/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5954 - acc: 0.5687 - val_loss: 1.9591 - val_acc: 0.4395\n",
      "Epoch 291/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5702 - acc: 0.5728 - val_loss: 1.9777 - val_acc: 0.4194\n",
      "Epoch 292/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5827 - acc: 0.5633 - val_loss: 1.9540 - val_acc: 0.4274\n",
      "Epoch 293/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5534 - acc: 0.6065 - val_loss: 1.9744 - val_acc: 0.4556\n",
      "Epoch 294/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5691 - acc: 0.5741 - val_loss: 1.9240 - val_acc: 0.4919\n",
      "Epoch 295/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5391 - acc: 0.5997 - val_loss: 2.0002 - val_acc: 0.4194\n",
      "Epoch 296/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5585 - acc: 0.5863 - val_loss: 1.9483 - val_acc: 0.4597\n",
      "Epoch 297/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5340 - acc: 0.5876 - val_loss: 2.0289 - val_acc: 0.4355\n",
      "Epoch 298/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5490 - acc: 0.5822 - val_loss: 1.9267 - val_acc: 0.4274\n",
      "Epoch 299/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5558 - acc: 0.5795 - val_loss: 1.9428 - val_acc: 0.4677\n",
      "Epoch 300/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5497 - acc: 0.5782 - val_loss: 1.8852 - val_acc: 0.4677\n",
      "Epoch 301/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5224 - acc: 0.5849 - val_loss: 1.9466 - val_acc: 0.4113\n",
      "Epoch 302/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5190 - acc: 0.5876 - val_loss: 1.9696 - val_acc: 0.4556\n",
      "Epoch 303/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5199 - acc: 0.5943 - val_loss: 1.9602 - val_acc: 0.3952\n",
      "Epoch 304/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5384 - acc: 0.5647 - val_loss: 1.9016 - val_acc: 0.4516\n",
      "Epoch 305/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5103 - acc: 0.6038 - val_loss: 1.9013 - val_acc: 0.4960\n",
      "Epoch 306/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5027 - acc: 0.6132 - val_loss: 1.9341 - val_acc: 0.4637\n",
      "Epoch 307/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5114 - acc: 0.5984 - val_loss: 1.9122 - val_acc: 0.4476\n",
      "Epoch 308/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5064 - acc: 0.6132 - val_loss: 1.8972 - val_acc: 0.4718\n",
      "Epoch 309/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5215 - acc: 0.5876 - val_loss: 1.9104 - val_acc: 0.4516\n",
      "Epoch 310/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4989 - acc: 0.5876 - val_loss: 1.9472 - val_acc: 0.4476\n",
      "Epoch 311/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4940 - acc: 0.6011 - val_loss: 1.9407 - val_acc: 0.4718\n",
      "Epoch 312/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4859 - acc: 0.6051 - val_loss: 1.9302 - val_acc: 0.4718\n",
      "Epoch 313/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5001 - acc: 0.5863 - val_loss: 1.8393 - val_acc: 0.4718\n",
      "Epoch 314/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4666 - acc: 0.6146 - val_loss: 1.9308 - val_acc: 0.4234\n",
      "Epoch 315/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4719 - acc: 0.6065 - val_loss: 1.9364 - val_acc: 0.4677\n",
      "Epoch 316/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4831 - acc: 0.6199 - val_loss: 1.8650 - val_acc: 0.5000\n",
      "Epoch 317/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4572 - acc: 0.6321 - val_loss: 1.8807 - val_acc: 0.4798\n",
      "Epoch 318/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4722 - acc: 0.5997 - val_loss: 1.8807 - val_acc: 0.4798\n",
      "Epoch 319/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4782 - acc: 0.6159 - val_loss: 1.8810 - val_acc: 0.4355\n",
      "Epoch 320/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4415 - acc: 0.6186 - val_loss: 1.8292 - val_acc: 0.5202\n",
      "Epoch 321/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4696 - acc: 0.6119 - val_loss: 1.8536 - val_acc: 0.4960\n",
      "Epoch 322/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4504 - acc: 0.6105 - val_loss: 1.8455 - val_acc: 0.4798\n",
      "Epoch 323/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4460 - acc: 0.6132 - val_loss: 1.8893 - val_acc: 0.4718\n",
      "Epoch 324/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4397 - acc: 0.6267 - val_loss: 1.8506 - val_acc: 0.4556\n",
      "Epoch 325/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4476 - acc: 0.6173 - val_loss: 1.9054 - val_acc: 0.4113\n",
      "Epoch 326/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4374 - acc: 0.6173 - val_loss: 1.8143 - val_acc: 0.4597\n",
      "Epoch 327/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4338 - acc: 0.6146 - val_loss: 1.9266 - val_acc: 0.4919\n",
      "Epoch 328/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4153 - acc: 0.6199 - val_loss: 1.8429 - val_acc: 0.4839\n",
      "Epoch 329/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4430 - acc: 0.6092 - val_loss: 1.8430 - val_acc: 0.5040\n",
      "Epoch 330/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4174 - acc: 0.6226 - val_loss: 1.8078 - val_acc: 0.4556\n",
      "Epoch 331/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4117 - acc: 0.6226 - val_loss: 1.8731 - val_acc: 0.4476\n",
      "Epoch 332/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4131 - acc: 0.6240 - val_loss: 1.8481 - val_acc: 0.4355\n",
      "Epoch 333/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4048 - acc: 0.6078 - val_loss: 1.8479 - val_acc: 0.4919\n",
      "Epoch 334/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3921 - acc: 0.6388 - val_loss: 1.8388 - val_acc: 0.4879\n",
      "Epoch 335/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4137 - acc: 0.6321 - val_loss: 1.7986 - val_acc: 0.5161\n",
      "Epoch 336/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3809 - acc: 0.6240 - val_loss: 1.7594 - val_acc: 0.4960\n",
      "Epoch 337/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3784 - acc: 0.6334 - val_loss: 1.8422 - val_acc: 0.4960\n",
      "Epoch 338/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4033 - acc: 0.6429 - val_loss: 1.8712 - val_acc: 0.4315\n",
      "Epoch 339/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4057 - acc: 0.6092 - val_loss: 1.8432 - val_acc: 0.4919\n",
      "Epoch 340/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4032 - acc: 0.6119 - val_loss: 1.8596 - val_acc: 0.4758\n",
      "Epoch 341/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3853 - acc: 0.6253 - val_loss: 1.7917 - val_acc: 0.5242\n",
      "Epoch 342/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3730 - acc: 0.6456 - val_loss: 1.8808 - val_acc: 0.4597\n",
      "Epoch 343/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3799 - acc: 0.6226 - val_loss: 1.7991 - val_acc: 0.4960\n",
      "Epoch 344/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3407 - acc: 0.6550 - val_loss: 1.8278 - val_acc: 0.5161\n",
      "Epoch 345/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3659 - acc: 0.6334 - val_loss: 1.8775 - val_acc: 0.4839\n",
      "Epoch 346/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3554 - acc: 0.6415 - val_loss: 1.8137 - val_acc: 0.5040\n",
      "Epoch 347/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3603 - acc: 0.6375 - val_loss: 1.8600 - val_acc: 0.4758\n",
      "Epoch 348/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3569 - acc: 0.6509 - val_loss: 1.8022 - val_acc: 0.4960\n",
      "Epoch 349/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3345 - acc: 0.6482 - val_loss: 1.8076 - val_acc: 0.4879\n",
      "Epoch 350/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3518 - acc: 0.6388 - val_loss: 1.7965 - val_acc: 0.4879\n",
      "Epoch 351/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3155 - acc: 0.6469 - val_loss: 1.7970 - val_acc: 0.4798\n",
      "Epoch 352/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3666 - acc: 0.6496 - val_loss: 1.7975 - val_acc: 0.4879\n",
      "Epoch 353/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3426 - acc: 0.6375 - val_loss: 1.8140 - val_acc: 0.4677\n",
      "Epoch 354/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3316 - acc: 0.6402 - val_loss: 1.8235 - val_acc: 0.5121\n",
      "Epoch 355/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3432 - acc: 0.6388 - val_loss: 1.7629 - val_acc: 0.5161\n",
      "Epoch 356/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3364 - acc: 0.6334 - val_loss: 1.7645 - val_acc: 0.4798\n",
      "Epoch 357/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3194 - acc: 0.6496 - val_loss: 1.8377 - val_acc: 0.4879\n",
      "Epoch 358/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3316 - acc: 0.6267 - val_loss: 1.7987 - val_acc: 0.5282\n",
      "Epoch 359/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3178 - acc: 0.6429 - val_loss: 1.7490 - val_acc: 0.5323\n",
      "Epoch 360/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3052 - acc: 0.6604 - val_loss: 1.7681 - val_acc: 0.4879\n",
      "Epoch 361/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3085 - acc: 0.6375 - val_loss: 1.7594 - val_acc: 0.5242\n",
      "Epoch 362/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3074 - acc: 0.6402 - val_loss: 1.7843 - val_acc: 0.4476\n",
      "Epoch 363/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3041 - acc: 0.6442 - val_loss: 1.8129 - val_acc: 0.4839\n",
      "Epoch 364/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2917 - acc: 0.6482 - val_loss: 1.8294 - val_acc: 0.4798\n",
      "Epoch 365/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2966 - acc: 0.6523 - val_loss: 1.7325 - val_acc: 0.5363\n",
      "Epoch 366/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2783 - acc: 0.6496 - val_loss: 1.7795 - val_acc: 0.4960\n",
      "Epoch 367/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2776 - acc: 0.6631 - val_loss: 1.7730 - val_acc: 0.5282\n",
      "Epoch 368/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2985 - acc: 0.6482 - val_loss: 1.7360 - val_acc: 0.5323\n",
      "Epoch 369/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3077 - acc: 0.6536 - val_loss: 1.7891 - val_acc: 0.4758\n",
      "Epoch 370/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2489 - acc: 0.6900 - val_loss: 1.7970 - val_acc: 0.4879\n",
      "Epoch 371/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2805 - acc: 0.6590 - val_loss: 1.7966 - val_acc: 0.4960\n",
      "Epoch 372/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2675 - acc: 0.6577 - val_loss: 1.7082 - val_acc: 0.5202\n",
      "Epoch 373/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2655 - acc: 0.6739 - val_loss: 1.7773 - val_acc: 0.5121\n",
      "Epoch 374/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2908 - acc: 0.6671 - val_loss: 1.7924 - val_acc: 0.4960\n",
      "Epoch 375/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2744 - acc: 0.6523 - val_loss: 1.7186 - val_acc: 0.5202\n",
      "Epoch 376/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2501 - acc: 0.6765 - val_loss: 1.6878 - val_acc: 0.5444\n",
      "Epoch 377/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2701 - acc: 0.6658 - val_loss: 1.7444 - val_acc: 0.5081\n",
      "Epoch 378/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2499 - acc: 0.6779 - val_loss: 1.7792 - val_acc: 0.5161\n",
      "Epoch 379/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2536 - acc: 0.6577 - val_loss: 1.7423 - val_acc: 0.5121\n",
      "Epoch 380/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2661 - acc: 0.6644 - val_loss: 1.7352 - val_acc: 0.5081\n",
      "Epoch 381/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2290 - acc: 0.6846 - val_loss: 1.7825 - val_acc: 0.4919\n",
      "Epoch 382/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2219 - acc: 0.6792 - val_loss: 1.7337 - val_acc: 0.5242\n",
      "Epoch 383/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2544 - acc: 0.6671 - val_loss: 1.8326 - val_acc: 0.4677\n",
      "Epoch 384/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2516 - acc: 0.6779 - val_loss: 1.7547 - val_acc: 0.5000\n",
      "Epoch 385/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2328 - acc: 0.6671 - val_loss: 1.7927 - val_acc: 0.4960\n",
      "Epoch 386/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2220 - acc: 0.6846 - val_loss: 1.7146 - val_acc: 0.5323\n",
      "Epoch 387/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2301 - acc: 0.6927 - val_loss: 1.7119 - val_acc: 0.5323\n",
      "Epoch 388/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2341 - acc: 0.6712 - val_loss: 1.7014 - val_acc: 0.5242\n",
      "Epoch 389/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2239 - acc: 0.6712 - val_loss: 1.7503 - val_acc: 0.5040\n",
      "Epoch 390/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2331 - acc: 0.6685 - val_loss: 1.7373 - val_acc: 0.5323\n",
      "Epoch 391/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2037 - acc: 0.6792 - val_loss: 1.7596 - val_acc: 0.4798\n",
      "Epoch 392/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2054 - acc: 0.6954 - val_loss: 1.6863 - val_acc: 0.5444\n",
      "Epoch 393/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2350 - acc: 0.6536 - val_loss: 1.7135 - val_acc: 0.5565\n",
      "Epoch 394/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2221 - acc: 0.6806 - val_loss: 1.7025 - val_acc: 0.5161\n",
      "Epoch 395/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2074 - acc: 0.6765 - val_loss: 1.6983 - val_acc: 0.5282\n",
      "Epoch 396/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1827 - acc: 0.6833 - val_loss: 1.6727 - val_acc: 0.5444\n",
      "Epoch 397/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2087 - acc: 0.6658 - val_loss: 1.6869 - val_acc: 0.5403\n",
      "Epoch 398/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1847 - acc: 0.6806 - val_loss: 1.6423 - val_acc: 0.5645\n",
      "Epoch 399/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1966 - acc: 0.6712 - val_loss: 1.7035 - val_acc: 0.5323\n",
      "Epoch 400/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1839 - acc: 0.6725 - val_loss: 1.7040 - val_acc: 0.5444\n",
      "Epoch 401/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1914 - acc: 0.6833 - val_loss: 1.7236 - val_acc: 0.5202\n",
      "Epoch 402/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1870 - acc: 0.6658 - val_loss: 1.7005 - val_acc: 0.5565\n",
      "Epoch 403/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1687 - acc: 0.7008 - val_loss: 1.7494 - val_acc: 0.5202\n",
      "Epoch 404/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1612 - acc: 0.6900 - val_loss: 1.7266 - val_acc: 0.5282\n",
      "Epoch 405/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1657 - acc: 0.6995 - val_loss: 1.7314 - val_acc: 0.5202\n",
      "Epoch 406/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1927 - acc: 0.6779 - val_loss: 1.7333 - val_acc: 0.5000\n",
      "Epoch 407/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1560 - acc: 0.6954 - val_loss: 1.7141 - val_acc: 0.5040\n",
      "Epoch 408/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1752 - acc: 0.6779 - val_loss: 1.6529 - val_acc: 0.5524\n",
      "Epoch 409/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1501 - acc: 0.7156 - val_loss: 1.7409 - val_acc: 0.5323\n",
      "Epoch 410/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1624 - acc: 0.6954 - val_loss: 1.7239 - val_acc: 0.5081\n",
      "Epoch 411/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1667 - acc: 0.6914 - val_loss: 1.6825 - val_acc: 0.5403\n",
      "Epoch 412/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1622 - acc: 0.6658 - val_loss: 1.6544 - val_acc: 0.5363\n",
      "Epoch 413/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1325 - acc: 0.6995 - val_loss: 1.6609 - val_acc: 0.5484\n",
      "Epoch 414/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1525 - acc: 0.6887 - val_loss: 1.6624 - val_acc: 0.5444\n",
      "Epoch 415/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1330 - acc: 0.7075 - val_loss: 1.7057 - val_acc: 0.5282\n",
      "Epoch 416/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1481 - acc: 0.6833 - val_loss: 1.6891 - val_acc: 0.5323\n",
      "Epoch 417/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1330 - acc: 0.6833 - val_loss: 1.7093 - val_acc: 0.5403\n",
      "Epoch 418/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1506 - acc: 0.7062 - val_loss: 1.7071 - val_acc: 0.5323\n",
      "Epoch 419/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1317 - acc: 0.6981 - val_loss: 1.6484 - val_acc: 0.5161\n",
      "Epoch 420/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1292 - acc: 0.6927 - val_loss: 1.6542 - val_acc: 0.5565\n",
      "Epoch 421/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1293 - acc: 0.7035 - val_loss: 1.6795 - val_acc: 0.5161\n",
      "Epoch 422/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1168 - acc: 0.6887 - val_loss: 1.6687 - val_acc: 0.5766\n",
      "Epoch 423/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1210 - acc: 0.7089 - val_loss: 1.7019 - val_acc: 0.5323\n",
      "Epoch 424/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1234 - acc: 0.6995 - val_loss: 1.6458 - val_acc: 0.5282\n",
      "Epoch 425/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1215 - acc: 0.7022 - val_loss: 1.6713 - val_acc: 0.5282\n",
      "Epoch 426/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0972 - acc: 0.7049 - val_loss: 1.6151 - val_acc: 0.5685\n",
      "Epoch 427/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1198 - acc: 0.7035 - val_loss: 1.6818 - val_acc: 0.5403\n",
      "Epoch 428/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.1192 - acc: 0.7116 - val_loss: 1.6102 - val_acc: 0.5685\n",
      "Epoch 429/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0899 - acc: 0.7116 - val_loss: 1.6726 - val_acc: 0.5605\n",
      "Epoch 430/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1022 - acc: 0.7237 - val_loss: 1.6490 - val_acc: 0.5121\n",
      "Epoch 431/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0991 - acc: 0.6995 - val_loss: 1.6448 - val_acc: 0.5565\n",
      "Epoch 432/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0965 - acc: 0.7102 - val_loss: 1.6674 - val_acc: 0.5565\n",
      "Epoch 433/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0735 - acc: 0.7237 - val_loss: 1.6946 - val_acc: 0.5282\n",
      "Epoch 434/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0952 - acc: 0.7183 - val_loss: 1.6245 - val_acc: 0.5363\n",
      "Epoch 435/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1059 - acc: 0.6927 - val_loss: 1.6078 - val_acc: 0.5524\n",
      "Epoch 436/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1081 - acc: 0.7116 - val_loss: 1.6106 - val_acc: 0.5645\n",
      "Epoch 437/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0788 - acc: 0.7143 - val_loss: 1.6773 - val_acc: 0.5282\n",
      "Epoch 438/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0659 - acc: 0.7183 - val_loss: 1.6572 - val_acc: 0.5444\n",
      "Epoch 439/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0714 - acc: 0.7237 - val_loss: 1.6094 - val_acc: 0.5605\n",
      "Epoch 440/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0621 - acc: 0.7156 - val_loss: 1.5702 - val_acc: 0.5847\n",
      "Epoch 441/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0516 - acc: 0.7251 - val_loss: 1.5838 - val_acc: 0.5645\n",
      "Epoch 442/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0669 - acc: 0.7237 - val_loss: 1.6997 - val_acc: 0.5363\n",
      "Epoch 443/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0577 - acc: 0.7197 - val_loss: 1.6307 - val_acc: 0.5202\n",
      "Epoch 444/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0442 - acc: 0.7358 - val_loss: 1.6100 - val_acc: 0.5645\n",
      "Epoch 445/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0630 - acc: 0.7022 - val_loss: 1.6317 - val_acc: 0.5242\n",
      "Epoch 446/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0712 - acc: 0.7278 - val_loss: 1.5905 - val_acc: 0.5645\n",
      "Epoch 447/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0529 - acc: 0.7358 - val_loss: 1.6063 - val_acc: 0.5645\n",
      "Epoch 448/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0512 - acc: 0.7264 - val_loss: 1.6127 - val_acc: 0.5323\n",
      "Epoch 449/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0487 - acc: 0.7089 - val_loss: 1.5721 - val_acc: 0.5645\n",
      "Epoch 450/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0566 - acc: 0.7143 - val_loss: 1.6637 - val_acc: 0.5444\n",
      "Epoch 451/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0424 - acc: 0.7332 - val_loss: 1.6321 - val_acc: 0.5484\n",
      "Epoch 452/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0370 - acc: 0.7264 - val_loss: 1.6025 - val_acc: 0.5363\n",
      "Epoch 453/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0420 - acc: 0.7156 - val_loss: 1.5104 - val_acc: 0.6008\n",
      "Epoch 454/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0353 - acc: 0.7372 - val_loss: 1.6096 - val_acc: 0.5847\n",
      "Epoch 455/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0302 - acc: 0.7278 - val_loss: 1.6265 - val_acc: 0.5444\n",
      "Epoch 456/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0407 - acc: 0.7183 - val_loss: 1.6076 - val_acc: 0.5685\n",
      "Epoch 457/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0145 - acc: 0.7385 - val_loss: 1.5630 - val_acc: 0.5927\n",
      "Epoch 458/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0156 - acc: 0.7385 - val_loss: 1.5684 - val_acc: 0.5524\n",
      "Epoch 459/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0336 - acc: 0.7264 - val_loss: 1.5740 - val_acc: 0.5645\n",
      "Epoch 460/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0177 - acc: 0.7143 - val_loss: 1.5586 - val_acc: 0.5766\n",
      "Epoch 461/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0227 - acc: 0.7358 - val_loss: 1.5678 - val_acc: 0.5847\n",
      "Epoch 462/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0087 - acc: 0.7251 - val_loss: 1.6385 - val_acc: 0.5685\n",
      "Epoch 463/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0130 - acc: 0.7264 - val_loss: 1.5745 - val_acc: 0.5685\n",
      "Epoch 464/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0152 - acc: 0.7264 - val_loss: 1.5568 - val_acc: 0.5323\n",
      "Epoch 465/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0167 - acc: 0.7210 - val_loss: 1.5467 - val_acc: 0.5887\n",
      "Epoch 466/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0209 - acc: 0.7345 - val_loss: 1.5688 - val_acc: 0.6129\n",
      "Epoch 467/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9946 - acc: 0.7358 - val_loss: 1.5661 - val_acc: 0.5524\n",
      "Epoch 468/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0168 - acc: 0.7332 - val_loss: 1.5584 - val_acc: 0.5524\n",
      "Epoch 469/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0014 - acc: 0.7520 - val_loss: 1.5644 - val_acc: 0.5806\n",
      "Epoch 470/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9791 - acc: 0.7372 - val_loss: 1.5712 - val_acc: 0.5685\n",
      "Epoch 471/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9837 - acc: 0.7426 - val_loss: 1.5421 - val_acc: 0.5565\n",
      "Epoch 472/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9679 - acc: 0.7466 - val_loss: 1.6043 - val_acc: 0.5363\n",
      "Epoch 473/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9959 - acc: 0.7251 - val_loss: 1.4899 - val_acc: 0.5645\n",
      "Epoch 474/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9707 - acc: 0.7574 - val_loss: 1.5721 - val_acc: 0.6008\n",
      "Epoch 475/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9692 - acc: 0.7574 - val_loss: 1.5292 - val_acc: 0.5605\n",
      "Epoch 476/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9642 - acc: 0.7507 - val_loss: 1.5627 - val_acc: 0.5645\n",
      "Epoch 477/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9589 - acc: 0.7547 - val_loss: 1.6327 - val_acc: 0.5524\n",
      "Epoch 478/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9902 - acc: 0.7399 - val_loss: 1.5329 - val_acc: 0.5766\n",
      "Epoch 479/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9538 - acc: 0.7588 - val_loss: 1.5665 - val_acc: 0.5524\n",
      "Epoch 480/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9584 - acc: 0.7318 - val_loss: 1.5626 - val_acc: 0.5887\n",
      "Epoch 481/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9575 - acc: 0.7588 - val_loss: 1.5044 - val_acc: 0.5645\n",
      "Epoch 482/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9521 - acc: 0.7480 - val_loss: 1.5607 - val_acc: 0.5887\n",
      "Epoch 483/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9622 - acc: 0.7493 - val_loss: 1.5704 - val_acc: 0.5806\n",
      "Epoch 484/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9489 - acc: 0.7453 - val_loss: 1.5236 - val_acc: 0.6290\n",
      "Epoch 485/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9561 - acc: 0.7520 - val_loss: 1.4945 - val_acc: 0.5847\n",
      "Epoch 486/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9476 - acc: 0.7480 - val_loss: 1.5618 - val_acc: 0.5726\n",
      "Epoch 487/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9491 - acc: 0.7439 - val_loss: 1.4890 - val_acc: 0.5968\n",
      "Epoch 488/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9676 - acc: 0.7399 - val_loss: 1.5376 - val_acc: 0.5847\n",
      "Epoch 489/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9328 - acc: 0.7588 - val_loss: 1.5353 - val_acc: 0.5887\n",
      "Epoch 490/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9384 - acc: 0.7534 - val_loss: 1.5596 - val_acc: 0.5605\n",
      "Epoch 491/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9473 - acc: 0.7507 - val_loss: 1.5467 - val_acc: 0.5806\n",
      "Epoch 492/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9485 - acc: 0.7628 - val_loss: 1.5105 - val_acc: 0.5645\n",
      "Epoch 493/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9326 - acc: 0.7453 - val_loss: 1.5173 - val_acc: 0.6250\n",
      "Epoch 494/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9245 - acc: 0.7574 - val_loss: 1.5134 - val_acc: 0.5968\n",
      "Epoch 495/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9254 - acc: 0.7655 - val_loss: 1.5669 - val_acc: 0.5685\n",
      "Epoch 496/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9592 - acc: 0.7278 - val_loss: 1.5085 - val_acc: 0.6008\n",
      "Epoch 497/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8947 - acc: 0.7709 - val_loss: 1.5027 - val_acc: 0.6008\n",
      "Epoch 498/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9208 - acc: 0.7561 - val_loss: 1.4961 - val_acc: 0.5968\n",
      "Epoch 499/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9234 - acc: 0.7736 - val_loss: 1.5617 - val_acc: 0.5444\n",
      "Epoch 500/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9135 - acc: 0.7695 - val_loss: 1.5497 - val_acc: 0.5887\n",
      "Epoch 501/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9159 - acc: 0.7682 - val_loss: 1.5572 - val_acc: 0.5484\n",
      "Epoch 502/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9187 - acc: 0.7426 - val_loss: 1.5391 - val_acc: 0.5766\n",
      "Epoch 503/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9040 - acc: 0.7655 - val_loss: 1.4724 - val_acc: 0.5847\n",
      "Epoch 504/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8984 - acc: 0.7668 - val_loss: 1.4445 - val_acc: 0.6048\n",
      "Epoch 505/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8899 - acc: 0.7561 - val_loss: 1.5869 - val_acc: 0.5484\n",
      "Epoch 506/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9020 - acc: 0.7561 - val_loss: 1.5718 - val_acc: 0.5565\n",
      "Epoch 507/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9070 - acc: 0.7507 - val_loss: 1.4572 - val_acc: 0.5806\n",
      "Epoch 508/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8843 - acc: 0.7709 - val_loss: 1.5273 - val_acc: 0.5968\n",
      "Epoch 509/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8856 - acc: 0.7615 - val_loss: 1.5464 - val_acc: 0.5847\n",
      "Epoch 510/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8902 - acc: 0.7628 - val_loss: 1.5094 - val_acc: 0.5927\n",
      "Epoch 511/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8952 - acc: 0.7682 - val_loss: 1.5187 - val_acc: 0.5685\n",
      "Epoch 512/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8819 - acc: 0.7642 - val_loss: 1.5030 - val_acc: 0.5806\n",
      "Epoch 513/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8880 - acc: 0.7709 - val_loss: 1.4585 - val_acc: 0.6089\n",
      "Epoch 514/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8876 - acc: 0.7776 - val_loss: 1.5454 - val_acc: 0.5968\n",
      "Epoch 515/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8948 - acc: 0.7493 - val_loss: 1.4644 - val_acc: 0.5927\n",
      "Epoch 516/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8493 - acc: 0.7938 - val_loss: 1.4953 - val_acc: 0.5968\n",
      "Epoch 517/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8653 - acc: 0.7844 - val_loss: 1.5530 - val_acc: 0.5927\n",
      "Epoch 518/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8648 - acc: 0.7695 - val_loss: 1.5012 - val_acc: 0.5968\n",
      "Epoch 519/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8786 - acc: 0.7736 - val_loss: 1.4644 - val_acc: 0.5968\n",
      "Epoch 520/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8792 - acc: 0.7736 - val_loss: 1.5532 - val_acc: 0.5524\n",
      "Epoch 521/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8653 - acc: 0.7803 - val_loss: 1.5115 - val_acc: 0.5685\n",
      "Epoch 522/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8553 - acc: 0.7857 - val_loss: 1.4900 - val_acc: 0.5887\n",
      "Epoch 523/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8393 - acc: 0.7844 - val_loss: 1.5802 - val_acc: 0.5645\n",
      "Epoch 524/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8843 - acc: 0.7601 - val_loss: 1.4966 - val_acc: 0.6169\n",
      "Epoch 525/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8511 - acc: 0.7668 - val_loss: 1.5125 - val_acc: 0.5968\n",
      "Epoch 526/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8461 - acc: 0.7951 - val_loss: 1.5653 - val_acc: 0.5766\n",
      "Epoch 527/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8542 - acc: 0.7763 - val_loss: 1.5045 - val_acc: 0.6129\n",
      "Epoch 528/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8402 - acc: 0.7871 - val_loss: 1.4634 - val_acc: 0.6089\n",
      "Epoch 529/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8583 - acc: 0.7817 - val_loss: 1.4552 - val_acc: 0.6129\n",
      "Epoch 530/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8352 - acc: 0.7857 - val_loss: 1.5039 - val_acc: 0.5806\n",
      "Epoch 531/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8569 - acc: 0.7803 - val_loss: 1.4616 - val_acc: 0.5806\n",
      "Epoch 532/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8643 - acc: 0.7763 - val_loss: 1.4526 - val_acc: 0.6048\n",
      "Epoch 533/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8328 - acc: 0.7817 - val_loss: 1.4414 - val_acc: 0.6089\n",
      "Epoch 534/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8269 - acc: 0.7925 - val_loss: 1.4490 - val_acc: 0.5927\n",
      "Epoch 535/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8370 - acc: 0.7682 - val_loss: 1.4875 - val_acc: 0.5968\n",
      "Epoch 536/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8285 - acc: 0.7803 - val_loss: 1.4723 - val_acc: 0.5968\n",
      "Epoch 537/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8270 - acc: 0.8032 - val_loss: 1.4650 - val_acc: 0.5927\n",
      "Epoch 538/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8262 - acc: 0.7830 - val_loss: 1.4677 - val_acc: 0.5806\n",
      "Epoch 539/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8292 - acc: 0.7925 - val_loss: 1.4787 - val_acc: 0.6089\n",
      "Epoch 540/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8004 - acc: 0.7965 - val_loss: 1.5598 - val_acc: 0.5806\n",
      "Epoch 541/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8333 - acc: 0.7898 - val_loss: 1.4467 - val_acc: 0.6089\n",
      "Epoch 542/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8168 - acc: 0.7965 - val_loss: 1.4358 - val_acc: 0.5887\n",
      "Epoch 543/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8159 - acc: 0.7911 - val_loss: 1.4874 - val_acc: 0.5726\n",
      "Epoch 544/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7930 - acc: 0.8046 - val_loss: 1.4721 - val_acc: 0.6089\n",
      "Epoch 545/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8209 - acc: 0.7898 - val_loss: 1.4845 - val_acc: 0.5847\n",
      "Epoch 546/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8173 - acc: 0.7817 - val_loss: 1.4652 - val_acc: 0.6169\n",
      "Epoch 547/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7998 - acc: 0.7992 - val_loss: 1.4811 - val_acc: 0.6048\n",
      "Epoch 548/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8052 - acc: 0.7898 - val_loss: 1.4155 - val_acc: 0.6089\n",
      "Epoch 549/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7988 - acc: 0.8019 - val_loss: 1.4856 - val_acc: 0.6129\n",
      "Epoch 550/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8114 - acc: 0.7790 - val_loss: 1.4568 - val_acc: 0.6169\n",
      "Epoch 551/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8078 - acc: 0.7871 - val_loss: 1.4257 - val_acc: 0.6008\n",
      "Epoch 552/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7772 - acc: 0.8019 - val_loss: 1.4157 - val_acc: 0.6210\n",
      "Epoch 553/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7665 - acc: 0.8113 - val_loss: 1.4554 - val_acc: 0.6008\n",
      "Epoch 554/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7995 - acc: 0.7911 - val_loss: 1.4315 - val_acc: 0.6210\n",
      "Epoch 555/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7921 - acc: 0.8073 - val_loss: 1.3912 - val_acc: 0.6371\n",
      "Epoch 556/600\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7716 - acc: 0.8100 - val_loss: 1.4278 - val_acc: 0.6089\n",
      "Epoch 557/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7734 - acc: 0.7978 - val_loss: 1.4039 - val_acc: 0.6129\n",
      "Epoch 558/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7918 - acc: 0.7965 - val_loss: 1.4379 - val_acc: 0.5887\n",
      "Epoch 559/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7683 - acc: 0.8181 - val_loss: 1.3960 - val_acc: 0.6169\n",
      "Epoch 560/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7786 - acc: 0.7938 - val_loss: 1.4262 - val_acc: 0.6008\n",
      "Epoch 561/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7614 - acc: 0.7978 - val_loss: 1.4194 - val_acc: 0.5968\n",
      "Epoch 562/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7789 - acc: 0.8032 - val_loss: 1.3622 - val_acc: 0.6008\n",
      "Epoch 563/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7809 - acc: 0.7830 - val_loss: 1.4390 - val_acc: 0.5968\n",
      "Epoch 564/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7658 - acc: 0.8019 - val_loss: 1.4290 - val_acc: 0.6048\n",
      "Epoch 565/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7681 - acc: 0.8086 - val_loss: 1.3511 - val_acc: 0.5968\n",
      "Epoch 566/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7660 - acc: 0.8086 - val_loss: 1.5026 - val_acc: 0.5645\n",
      "Epoch 567/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7557 - acc: 0.8086 - val_loss: 1.3952 - val_acc: 0.6492\n",
      "Epoch 568/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7688 - acc: 0.8032 - val_loss: 1.4776 - val_acc: 0.5968\n",
      "Epoch 569/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7526 - acc: 0.7965 - val_loss: 1.4161 - val_acc: 0.6210\n",
      "Epoch 570/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7376 - acc: 0.8100 - val_loss: 1.3576 - val_acc: 0.6331\n",
      "Epoch 571/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7471 - acc: 0.8127 - val_loss: 1.4080 - val_acc: 0.6169\n",
      "Epoch 572/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7526 - acc: 0.7925 - val_loss: 1.4239 - val_acc: 0.6169\n",
      "Epoch 573/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7546 - acc: 0.8059 - val_loss: 1.4881 - val_acc: 0.5847\n",
      "Epoch 574/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7519 - acc: 0.7911 - val_loss: 1.3874 - val_acc: 0.6169\n",
      "Epoch 575/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7446 - acc: 0.8140 - val_loss: 1.3908 - val_acc: 0.6331\n",
      "Epoch 576/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7532 - acc: 0.7992 - val_loss: 1.4744 - val_acc: 0.5927\n",
      "Epoch 577/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7239 - acc: 0.8154 - val_loss: 1.3891 - val_acc: 0.6210\n",
      "Epoch 578/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7414 - acc: 0.8113 - val_loss: 1.4736 - val_acc: 0.6169\n",
      "Epoch 579/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7274 - acc: 0.8221 - val_loss: 1.4299 - val_acc: 0.6129\n",
      "Epoch 580/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7330 - acc: 0.8059 - val_loss: 1.4171 - val_acc: 0.6008\n",
      "Epoch 581/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7300 - acc: 0.8046 - val_loss: 1.4720 - val_acc: 0.5685\n",
      "Epoch 582/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7299 - acc: 0.8127 - val_loss: 1.4027 - val_acc: 0.6290\n",
      "Epoch 583/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7220 - acc: 0.8288 - val_loss: 1.3568 - val_acc: 0.6371\n",
      "Epoch 584/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7381 - acc: 0.7925 - val_loss: 1.4919 - val_acc: 0.6129\n",
      "Epoch 585/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7147 - acc: 0.8315 - val_loss: 1.3854 - val_acc: 0.6290\n",
      "Epoch 586/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7164 - acc: 0.8100 - val_loss: 1.4293 - val_acc: 0.6169\n",
      "Epoch 587/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7224 - acc: 0.8235 - val_loss: 1.4215 - val_acc: 0.5968\n",
      "Epoch 588/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7140 - acc: 0.8235 - val_loss: 1.3730 - val_acc: 0.6331\n",
      "Epoch 589/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6950 - acc: 0.8356 - val_loss: 1.4064 - val_acc: 0.6169\n",
      "Epoch 590/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7210 - acc: 0.8140 - val_loss: 1.4212 - val_acc: 0.5927\n",
      "Epoch 591/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6984 - acc: 0.8235 - val_loss: 1.3670 - val_acc: 0.6492\n",
      "Epoch 592/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7014 - acc: 0.8194 - val_loss: 1.4360 - val_acc: 0.5766\n",
      "Epoch 593/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7136 - acc: 0.8261 - val_loss: 1.4121 - val_acc: 0.5968\n",
      "Epoch 594/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6932 - acc: 0.8208 - val_loss: 1.4132 - val_acc: 0.6089\n",
      "Epoch 595/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.8113 - val_loss: 1.3652 - val_acc: 0.6129\n",
      "Epoch 596/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6929 - acc: 0.8302 - val_loss: 1.4244 - val_acc: 0.6250\n",
      "Epoch 597/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6947 - acc: 0.8329 - val_loss: 1.4318 - val_acc: 0.5927\n",
      "Epoch 598/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6851 - acc: 0.8383 - val_loss: 1.3662 - val_acc: 0.6371\n",
      "Epoch 599/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6977 - acc: 0.8235 - val_loss: 1.4198 - val_acc: 0.6048\n",
      "Epoch 600/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.8235 - val_loss: 1.3832 - val_acc: 0.6048\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_x,train_y,\n",
    "                 epochs=600,\n",
    "                 batch_size=128,\n",
    "                 validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15b77a02220>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch,history.history.get('acc'),label='acc')\n",
    "plt.plot(history.epoch,history.history.get('val_acc'),label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
